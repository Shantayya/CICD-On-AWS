Jenkins open source automation server that is used to automate all sort of tasks related to building(maven), testing(Junit), delivering and even deploying the software.

Jenkins Plugins:
Jenkins has plugin repository where you can download .hpi file and upload it your server. Manage jenkins --> manage plugins --> Advanced
or copy to plugin directory /var/lib/jenkins

Master-Slave architecture:
A Standalone Jenkins instance can grow quickly into disk-munching,cpu eating monster. To prevent this from happening we can scale Jenkins by implementing a slave node architecture,which can help us offload some of responsibilities of master jenkins instance. 

Jenkins master:
1. Holds all key configuration
2. Acts like controller or orchestrator
3. Sheduling and monitoring build tasks 
4. Dispatching build to slaves
5. Monitor the slaves etc

Jenkins slave:
1. Java executable that runs on remote machine
2. Listen to requests from master and executes build jobs
3. Slaves can run on variety of OS etc

static agents:			dynamic agents:
vm (nodes)			container or pods (cloud)

Note: Jenkins master node uses JNLP(Java network launch protocol) service on port 50000 to connect to slaves for dispatching jobs. /var/jenkins_home is deafult jenkins home when used container and /var/lib/jenkins/ if use jenkins as service. 

----Run Jenkins as docker container----
usermod -aG docker jenkins		--> adding jenkins user to docker group so that jenkins user can access docker. 
newgrp docker				--> reloading docker group	
docker volume create jenkins_home
docker run -d --name Jenkins -v jenkins_home:/var/jenkins_home -p 8080:8080 -p 50000:50000 --restart always jenkins/jenkins:lts-jks11

docker exec -it Jenkins cat /var/jenkins_home/secret/initialAdminPassword 		--> to see jenkins login password

---run Jenkins as service---
sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install java-openjdk11 -y

add jenkins repo, install using yum and start system services 

logs: /var/log/jenkins/jenkins.log
configuration parameter available at: /etc/sysconfig/jenkins like to change JENKINS_HOME


----Jenkins job-----
Sequential set of tasks that user defines. ex: a Job can fetch source code from version control,build the code,run unit tests etc
job is synonymous with project. 
Jenkins support 2 types of jobs boradly:
1. Freestyle			--> default job types in jenkins. includes ad-hoc tasks,running shell commands, invoke ansible playbook etc
2. Pipeline			--> series of build steps

number of job types depends on the plugin that you have installed. ex: maven project/job is only available if you installed the maven plugin. 
other job types include:
3. multibranch pipeline 
4. Folder					--> not a job type rather a way how you arrange jobs. 
5. Multiconfiguration project


--Env variables---
in Jenkins Pipeline, there are lot of env variables  that can  be accessed and maintained during buid execution. can be seen at jenkins-url/env-vars.html
ech "JOB_NAME=${JOB_NAME}"

---Manage Jenkins--- (core configuration stored in config.xml under /var/lib/jenkins)
system configuration:
1. configure system (now system): configure gobal settings(email(normal and extended) notification, global properties like env var,tools locations etc,system msg to promulgate msg for jenkins users like maintainance,executors(number of vCPU's) shows number of jobs can run at a time, quite period(buffer time to kick off jobs),SCM checkout retry count,Jenkins URL, and paths (JDK).

2. global tool configuration (tools): configure the paths of the tools which you integrate with jenkins. provides auto installation also
3. Manage plugins: Jenkins functionality can be extended through plugins. Plugins provide additional features and integrations with various tools. Mostly Jenkins server will not have opened to iternet so use plugin manager to configure proxy settings so that Jenkins can connect to internet to download Plugins. 

4. manage nodes and cloud: manage configuration of nodes (adding new node,configure their usage (number of executors,label), specify target node for job execution etc)

Note: 0 in executor specify no job will run on master. we can specify label to run jobs on slave always. 

security:
1. credentials: 
	1. username and password
	2. certificate
	3. ssh username with privateKeys
	4. seret text
	5. secret file

2. Configure global security	--> authorization --> matrix baed security 
3. manage users
4. configure credential provider

status information


-----------------Freestyle Jobs----------------
default job types in jenkins. they are highly configurable through UI and allow you define ad-hoc tasks(scp,docker run),running shell commands, invoke ansible playbook clone git etc

General:
1. description
2. Discard old builds (days + number of builds to keep)
3. GitHub project
4. This project is parameterized
5. Throttle builds
6. Execute concurrent builds if necessary
7. Restrict where this project can be run (labels)
8. Advanced: Quite period,retry count,Block build if upstream/downstream project is building,use custome workspace [checkboxes]

SCM:
1. None
2. Git

Build Triggers:
1. Trigger builds remotely (from script)
2. Build after other projects are build (upstream and downstream jobs)
3. Build periodically  (cronjob)
4. GitHub hook trigger for GitSCM polling
5. Poll SCM (cronjob) but build only if any SCM changes. 

Note: 3 and 5 both are cron jobs however 3rd run the job on mentioned time irrespective of any change in gitHub repo. 5th will try to run the job on mentioned time only if any change in gitHub repo otherwise skip.  

Build Environment:
1. Delete workspace before build starts
2. Use secret text or fields			--> env variable with all types of credentials(mentioned in global credentials menu). use this env var in shell
3. Add timestamp  to the console output
4. Inspect build log for published build scans
5. Terminate build if its stuck (gives timeout time)
6. with Ant

Build steps:
1. Execute shell/windows
2. Invoke Ant/Gradle script
3. Invoke top level maven 		--> if Maven integration plugin
4. Run with timeout

Post Build actions:



---Git Integration with Jenkins-----
1. download Git in Jenkins vm if Jenkins running as service
2. provide GIT path as PATH env variable under global properties section of configure system section
3. use shell under build steps (git clone $USER:$PASS@url)		--> $USER and $PASS env var defined under build environment --> secret text or fields

or 
1. manage jenkins --> plugin --> download GIT without restart
2. provide Git executable path in Global tool configuration under GIT section if GIT already exist on jekins machine or auto download
3. check SCM  --> Git option by providing repo url and branch 


----Maven integratin with Jenkins----
1. download maven in jenkins machine
2. provide Maven path as PATH env variable under global properties section of configure system section
3. use shell under build step to build maven projects by specifying maven goals

or
1. manage jenkins -> plugins --> download maven integration plugin
2. manage jenkins --> global tool configuration --> maven configuration section --> provide maven variable name and path if maven is already available in jenkins machine otherwise select auto download with correct maven version 
3. select invoke top level maven under build steps by specifying goals




----Trigger jobs remotely through script,curl,postman----
ask for authentication token	--> provide any value like test123
JENKINS_URL/jobs/jobname/build?Token=TOKEN_NAME(above value)	or /buildWithParameters?Token=TOKEN_NAME		--> use to remotely trigger job


1. Through curl
Trigger jobs through curl requires authentication with jenkins with username and token so manage Jenkins --> security --> manage users --> click on user(say admin) --> configure --> API token --> create one
curl --user admin(user):token JENKINS_URL/jobs/jobname/build?Token=test123
curl -X POST -d 			--> if build with parameter

2. postman
put above endpoint in GET and provide username and token under authrization 

3. script --> in postman --> code snippet --> select any language to create script 
config.json
{
"username":"admin"
"token":"tokenvalue"
"jenkins_url":"JENKINS_URL"
"job_name":"RemoteTrigger"
"job_token":"test12"
}


main.py
#import libraries
import json
import os
import requests

#read config file
dir_path = os.path.dirname(os.path.realpath(__file__))			--> returns path of config.json file
configFile = open(dir_path + "/config.json","r")
configContent = configFile.read()					--> returns string
jsonConfigContent = json.loads(configContent)				--> return json as key-value pair (type will be dict)

#parse config file
jenkins_url = jsonConfigContent('jenkins_url')
user = jsonConfigContent('username')
token = jsonConfigContent('token')
job_name = jsonConfigContent('job_name')
job_token = jsonConfigContent('job_token')

#trigger job
URL = jenkins_url+'/jobs/'+job_name+'/build?token='+job_token
response = requests.post(URL, auth=(user,token))

#check status code
if response.status_code == 201:
   print("SUCCESS")
else:
   print("FAILURE")


------------------------------------Jenkins GitHub webhook interation-----------
Webhooks are one of the ways web application can communicate with each other. it allows you to send real time data from one apps to another whenever a given event occurs. 

webhook vs API
With API you get data through a process known as polling.  this is when your application periodically makes a request to an API server to check for new data. ex. weather apps
Webhook, pushes the data to receiving application as soon as an event occur. thats why called as reverse API. 

GitHub repo --> settings --> webhook --> add webhook --> JENKINS_URL/github-webhook/			--> in recent deliveries you can see github shares payload with jenkins 


-----Generic webhook trigger to parse webhook payload----------
we can use the generic webhook trigger plugin to parse webhook payload to trigger jenkins jobs based on particular action like PR opened or closed etc in github by filtering the webhook payloads in jenkins

jobs --> job_name --> configure -> generic-webhook --> provide token value --> post content parameters (variable like ACTION,expression like $.action)--> optional filter (expression like opened, text like $ACTION) --> build steps

repo --> settings --> webhook --> add webhook --> JENKINS_URL/generic-webhook-trigger/invoke?Token=TOKEN_VALUE 


------------------------------------Folder properties plugin---------------------------
Allows user to define properties for folder which can then be used by any jobs contained within it or any of its sub-folder. 



---------------------------------Build with parameters--------------------------
Build parameters allows you to pass data into jenkins job. Supported parameters include Strings, Boolean, choices, Files,Credentials, password, URL to another job etc. 
In FreeStyle job,you can access parameter just like any env variable ${PARAMETER_NAME}

curl --user admin(user):token "JENKINS_URL/jobs/jobname/buildWithParameter?Token=test123&IMAGE_NAME=test&IMAGE_TAG=1.11&ENVIRONMENT=PROD"
curl -X POST --user admin(user):token "JENKINS_URL/jobs/jobname/build?Token=test123" --data "IMAGE_NAME=test&IMAGE_TAG=1.11&ENVIRONMENT=PROD"

---Active choices plugin---
used in parameterized freestyle jenkins job to create scripted,dynamic and interactive job parameters. Active choices parameters can be dynamically updated and can be 
rendered as combo-boxes, radio buttons or rich html UI widgets. 

active-reactive parameters:
State			cities
Maharashtra		Pune,Mumbai,Nagpur
UP			Waranasi,Lukhnow,NCR
MP			Indore,Bhopal


trigger buid with parameters job remotely:
config.json
{
"username":"admin"
"token":"tokenvalue"
"jenkins_url":"JENKINS_URL"
"job_name":"RemoteTrigger"
"job_token":"test12"
"isTheJobParameterized: "True"
"my_data":{
"DOCKERHUB_USERNAME":"Shantayya"
"TAG":"5.55"
"PUSH":"true"
"DEPLOY_TO":"PROD"
   }
}
main.py
#import libraries
import json
import requests
imort requests.auth
import HTTPBasicAuth

#read json file
withOpen("config.json","r") as f:
 data = json.load(f)

#parse json file
jenkins_url = data["jenkins_url"]
user = data["username"]
token = data["token"]
job_name = data["job_name"]
job_token = data["job_token"]
parameterized = data["isTheJobParameterized"]

#call remote job
if parametrized:
  URL = jenkins_url+'/jobs/'+job_name+'/buildWithParameter?token='+job_token
  my_data = data["my_data"]
else:
  URL = jenkins_url+'/jobs/'+job_name+'/build?token='+job_token
  my_data = None

result = requests.post(URL,auth=HTTPBasicAuth(user,token),data = my_data)

#status code
if int(result.status_code) == 201:
 print("Job Executed")
else:
 print("Job Failed")



-------------------------Jenkins Tomcat integration--------------
tomcat installation:
cd /opt
curl -O https://URL/apache-tomcat-9.0.56.tar.gz
tar -xzvpf apache-tomcat-9.0.56.tar.gz
mv apache-tomcat-9.0.56 tomcat9
echo "export CATALINA_HOME="/opt/tomcat9" >>~/.bashrc
source ~/.bashrc


start---> cd /opt/tomcat9/bin	--> ./startup.sh
access --> Access tomcat from your browser at http://<IP-Address>:8080  change port at conf/server.xml

add users --> add users and role at conf/tomcat-users.xml
enable remote access --> at webapps/manager/META-INF/context.xml

Manage jenkins --> manage plugins --> depoy to container plugin 
add tomcat credentials in manage jenkins --> security --> credentials  --> Global --> add credentials 

freestyle job --> post build actions --> deploy war to container --> 
WAR/EAR Files: 
context path: 
containers --> credentials + Tomcat URL


--------------------MailHog SMTP Jenkins integration-----------------
MailHog is an email testing tool  for developers. It allows to configure your application  to use MailHog for SMTP delivery.
MailHog runs with SMTP port 1025 and web interface on 8025. 

docker run -d -p 1025:1025 -p 8025:8025 --name mail mailhog/mailhog
manag jenkins --> configure system --> system configuration --> email notification --> add SMTP server and port details with recepient,default content etc

jobs --> configure --> post build tasks --> select email notification 

 
--------------------------Update Jenkins build status badge on GitHub-----------------
Manage Jenkins --> manage plugins --> embeddable build status plugin 
Goto FreeStyle job with SCM --> click on Embeddable build status --> copy one of markdown url in Git readme.md file 


--------------------Update Jenkins build status in GitHub Pull Request----------------
Generic-webhook trigger plugin needed to parse webhook payload to trigger jenkins jobs based on particular action like PR opened or closed etc in github by filtering the webhook payloads in jenkins
Post Build task plugin --> allowed to execute shell task depending on build log output. 

1. add webhook in github for PR open
jobs --> job_name --> configure -> generic-webhook --> provide token value --> post content parameters (variable like ACTION,expression like $.action)--> optional filter (expression like opened, text like $ACTION) --> build steps

repo --> settings --> webhook --> add webhook --> JENKINS_URL/generic-webhook-trigger/invoke?Token=TOKEN_VALUE 

2. send Jenkins build status to jenkins
Build actions --> post build task --> Log text as SUCCESS/FAILURE, script as below command  

curl -u USERNAME:USER_TOKEN(GitHub) -X POST "https://api.github.com/repos/GITHUB_USERNAME/REPO_NAME/statuses/COMMIT_ID" -H
"Accept: application /vnd.github.v3+json" -d 
"{\"state\": \"SUCCESS/FAILURE\", 
\"context\": \"ANY MESSEGE\",
\"description\":\"Jenkins\",
\"target_url\":\"JENKINS_URL/job/$JOB_NAME/$BUILD_NUMBER/console\" }"

curl -u shantayya:ghp_www -X POST "https://api.github.com/repos/shantayya/maven-webapp/statuses/$GIT_COMMIT" -H "Accept: application/vnd.github.v3+json"
-d "{
\"state\":\"success\",
\"context\":\"Continuous Integration\",
\"description\":\"Jenkins\",
\"target_url\":\"JENKINS_URL/job/$JOB_NAME/$BUILD_NUMBER/console\"
}"

refer: 
https://docs.github.com/en/rest/using-the-rest-api/getting-started-with-the-rest-api?apiVersion=2022-11-28
https://docs.github.com/en/rest/commits/statuses?apiVersion=2022-11-28#create-a-commit-status



-------------------Nexus Jenkins integration------------------------
manage jenkins --> manage plugins --> download nexus platform plugin
manage jenkins --> configure system --> system --> add Sonartype Nexus server details and save
create freestyle job --> configure --> build steps --> Nexus repository manager publisher --> select details from drop down(it will list repos availabe on nexus)

Note: under TAG, Snapshot version artifact will not be send to nexus repo from nexus 3 onwards. 


---------------------SonarQube Integration with Jenkins--------------
1. manage jenkins --> manage plugins --> downlaod sonarqube scanner plugin 
2. manage jenkins ---> configure system --> system configuration --> add Sonarqube Server details and add sonarqube server credentials under global credentials security section of managed jenkins 
3. manage jenkins --> global tool configuration --> provide sonar scanner path if scanner already exist in jenkins machine otherwise auto download
4. create freestyle job ---> configure --> build steps --> select execute sonarqube scanner --> provide sonar-project.properties file or provide all properties in text box
 


-------------------------Jenkins pipeline-----------------------------
Pipeline is series of events or tasks which are interconnected in particular order. in simple words, its combination of plugins that support integration and implementation of continuous delivery pipelines. 
DSL (domain specific lang) specialized to particular apps domain like HTML for web pages etc

definition of jenkins pipeline is written into text file called as Jenkinsfile. can be constructed in 2 ways,
1. Declarative Pipeline		--> very easy to understand and write 
pipeline{ 
 agent any
 stages {
   stage('Build'){steps{}}
   stage('Deploy'){ steps{script{}} }			--> script block helps to run groovy code inside declarative pipeline. 
  }
}
2. Scripted Pipeline (Groovy)	--> very powerful however need skilled resource and makes pipeline complicated
node{
stage('Build'){ steps {} }
stage('deploy'){steps {} }
 }

node/agent is crutial as it allocates an executor and workspace for pipeline. 

Node: Use Groovy sandbox if checked, runs the script in sandbox with limited abilities. if unchecked and you are not admin then you need to wait for admin approval for script execution. 
PATH=$PATH:$M2_HOME/bin
/usr/bin:/usr/sbin/:/opt/maven/bin		--> in Pipeline PATH=$PATH will not resolve so we use PATH+EXTRA in env variable or use withEnvironment


----shell commands inside pipeline-----
pipeline{
 agent any
 stages{
   stage('Build'{
     steps{
        sh 'mvn clean'			--> When you use the sh step in a Jenkins pipeline, it's a built-in step (plugin) that allows you to execute shell commands
	sh '''				--> execute multiple commands 
		----------
		--------
 	   '''
           }
         }
     }
 }

-------------Timeout and retries------
We cab retry certain steps in pipeline if they are failing or exit if steps take too long. (timeout)
when step cannot be completed then timeout help the controller avoid wasting resources and release executors. 
syntax: options {timeout(time: 1,unit: 'HOURS')}
	options {retry(3)}

pipeline{
  agent any
  options {
     timeout(time:1, unit:'HOURS')}
     retry(3)					--> global entry
    }
  stages{
    stage('Deploy'){
      steps{
              retry(3){							--> stage level options
                          sh './flaky.sh'
                      }
            timeout(time:3, unit: 'MINUTES'){
             sh './healthcheck.sh'
          }
       }
    }
}


----Post build steps------
post{
  always{
    echo 'This will run always' 
        }
  success{
     echo 'This will run only if job success'
         }
  failure{
     echo 'This will run only if job fails'
         }
  unstable{
     echo 'This will ony run if job turns to unstable'
         }
  changed{
      echo 'This will run only if job status has changed. be it from success to failure and vice versa'
         }
    }


-------------Environment variable--------
pipeline{
  agent any
  tools{
    maven 'M3'						--> use maven tool if maven path is set in gloabal tool conf so no need to witEnv() wrapper to specify mvn path 
      }
  environment{						--> use globally
   USE_JDK='true'
   JDK_HOME='/opt/jdk1.8.0_333'
   DB_ENGINE='sqlite'
   GIT_CREDS = credentials('GIT_USR_PASS')		--> GIT_USR_PASS credential mentioned in security--> credentials section
      }
   stages{
     stage('Print Env variables'){	
             environment{ ----}				---> stage level
             steps{
                   echo '${DB_ENGINE}' or $DB_ENGINE or ${env.DB_ENGINE}
		   echo '${GIT_CREDS_USR}'	
	           echo '${GIT_CREDS_PASS}'
                  }
           }
         }
     stage('Build'){
       staps{
          withEnv(['PATH+EXTRA=/opt/maven/bin']){	--> use withEnv() wrapper if tools path is not mentioned in global tool configuration. generate withEnv using pipeline syntax generator
              sh 'mvn clean install'
             }
          }
       }
 }


Note: if var contains username and password then we can use var_USR and var_PASS to separate username and password in jenkins. 

1. credentials()					--> expose sensitive info in logs plus globa scope if defined in global environment block
GIT_CREDS = credentials('GIT_USR_PASS')
curl -u GIT_CREDS_USR:GIT_CREDS_PASS 'URL'

2. using withCredentials()				--> not expose plus limited scope
withCredentials([usernamePassword(crdentialsId:'git_usr_pass', passwordVariable:'Y', usernameVariable:'X')])
 {
   curl -u $X:$Y 'URL'
 }

while both methods achieve the same purpose, using withCredentials() is often considered a best practice for handling credentials in Jenkins pipelines.


------Deploying on pods------
1. install kubectl on jenkins(running as service) machine  and put kubectl executable in /usr/bin and provide executable permission for kubectl
2. declare PATH variable in manage jenkins --> configure systems --> system configurations --> environment properties --> PATH
3. downlaod kubeconfig file from digital ocean and create secret file from manage jenkins --> security --> credentials --> dc_kc
4. create pipeline job
pipeline{
  agent any								--> When you use agent any, Jenkins will dynamically allocate an available agent (which, in 									this case, could be a Kubernetes pod) to execute the pipeline stages. This flexibility allows 									Jenkins to choose any available agent that meets the requirements of the pipeline stages.
  environment{
   my_config = credentials('dc_kc')
      }
  stages{
    stage('Get Pods'){
      steps{
              sh 'kubectl --kubeconfig=$my_config get pods'
            }
        }
    }
}

Note: here we have to provide --kubeconfig everytime we execute kubectl command 

--using kubenetes CLI plugin---
1. install kubectl on jenkins machine  and put kubectl executable in /usr/bin and provide executable permission for kubectl
2. manage jenkins--> manage plugins --> kubenetes cli
3. create secret file from manage jenkins --> security --> credentials --> dc_kc (file having kubeconfig file)
4. create pipeline job
pipeline{
  agent any
  stages{
    stage('Get Pods'){
      steps{
	  script{
		withKubeConfig([credentialsId='dc_kc']){		--> withKubeConfig() wrapper is scripted syntax so used in script block
   	           sh 'kubectl get pods'
        	    }
		}
        }
    }
  }
}


Note: if we have to use helm then install it on jenkins machine and follow remaining steps from 2 to 4.
kubeconfig file handles the authentication and access to the Kubernetes cluster, and no additional service account or role binding is needed within the Kubernetes cluster for Jenkins in this specific pipeline configuration. 



--------Push maven artifacts to Nexus repository---------------
We need Sonatype Nexus Artifact Uploader(for uploading artifact) and Pipeline Utility Steps (for fetching artifact detaits from pom) plugins to download in jenkins. 
referrence: https://blog.sonatype.com/workflow-automation-publishing-artifacts-to-sonatype-nexus-using-jenkins-pipelines

pipeline{
  agent any
  tools{
  maven 'M3'
      }
  environment{
     NEXUS_VERSION = "nexus3"
     NEXUS_PROTOCOL = 'http"
     NEXUS_URL="http://ip:8081"
     NEXUS_REPOSITORY="maven-nexus-repo"
     NEXUS_CREDENTIAL_ID = "nexus credentials"
    }
   stages{
       stage('Clone Repo"{
              steps{
                   git branch: 'master',
                   url: 'url"
                   }
                }
       stage('Build'){
             steps{
                sh 'mvn -DskipTests/-Dmaven.test.failure.ignore=true clean package'
                  }
               }
        stage('Push artifact to Nexus'){
             steps{
                script{
                    pom = readMavenPom file: "pom.xml";
                    filesByGlob = findfiles(glob: "target/*.${pom.packaging}");
                    echo "${filesByGlob[0].name} ${filesByGlob[0].path} ${filesByGlob[0].directory} ${filesByGlob[0].length} ${filesByGlob[0].lastModified}"
                    artifactPath = filesByGlob[0].path;
                    artifactExists = fileExists artifactPath;
                    if(artifactExists){
                         echo "****File: ${artifactPath}, group: ${pom.groupId}, packaging: ${pom.packaging}, version: ${pom.version}";
                         nexusArtifactUploader(
                              nexusVersion: NEXUS_VERSION,
			      nexusProtocol: NEXUS_PROTOCOL,
                              nexusUrl: NEXUS_URL,
			      groupId: pom.groupId,
                              version: pom.version,
 			      repository: NEXUS_REPOSITORY,
                              credentialId: NEXUS_CREDENTIAL_ID,
                              artifacts: [
                                   [artifactId: pom.artifactId,
                                    classifier: '',
                                    file: artifactPath,
                                    type: pom.packaging],
                                    
                                    [artifactId: pom.artifactId,
                                    classifier: '',
                                    file: pom.xml,
                                    type: pom]

					]
				);
			}else{
                                 error "*** File: ${artifactPath}, could not be found";
                         }
                   }
	   }
    }


Nexus push via CURL
referrence : 
https://support.sonatype.com/hc/en-us/articles/115006744008-How-can-I-programmatically-upload-files-into-Nexus-3-

withCredentials([usernamePassword(credentialsId: 'CREDS', passwordVariable: 'PASS', usernameVariable: 'USER')]) {
    sh "curl -v -u $USER:$PASS --upload-file target/${pom.artifactId}-${pom.version}.${pom.packaging} \
    http://NEXUS-SERVER-URL/repository/maven-hosted/org/springframework/samples/${pom.artifactId}/${pom.version}/${pom.artifactId}-${pom.version}.${pom.packaging}"
}


--------------Using K8s pods as Jenkins build agents-------------------------
If you are not using a kubeconfig file then need to set up a service account, role, and role binding for Jenkins within your Kubernetes cluster so that Jenkins which is running as service out of K8s cluster will talk to K8s cluster. 

#Jenkins-sa.yaml:
apiVersion: v1
kind: ServiceAccount
metadata:
  name: Jenkins-sa

#Jenkins-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: Jenkins-role
rules:
  apiGroups: [""]
  resources: ["pods","pods/exec,"pods/log"]
  verbs: ["get","list","watch","create","patch","update","delete"]

#Jenkins-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: Jenkins-role-binding
subjects:
- kind: ServiceAccount
  name: Jenkins-sa
rolRef:
  kind: Role
  name: Jenkins-role
  apiGroup: rbac.authorization.k8s.io

kubectl apply -f Jenkins-sa.yaml
kubectl apply -f Jenkins-role.yaml
kubectl apply -f Jenkins-role-binding.yaml

pipeline{
  agent{
    kubernetes{
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
       '''}
     }
    stages{
        stage('Checkout SCM'){
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
              }
         }
  }


Note: if you want to run Jenkins as container then use helm chart to install jenkins. Jenkins if running as pod then it always spins JNLP container within all slave pods for communication and JNLP container runs on port 50000. when we install jenkins using helm chart, JNLP container template configuration are in built. 


-----------------------inheritFrom concept-------------------------------
In Jenkins pipelines, when using Kubernetes pods as agents, the "inheritFrom 'default pod template name'" statement is used to inherit configuration settings from a predefined pod template defined in jenkins. This is a way to reuse a set of common configurations for multiple agents.

Here's how it typically works:
1. Jenkins Master Setup:
Jenkins, running in a container or another deployment in your Kubernetes cluster, has access to DockerHub.
Jenkins is configured with the default pod template, which includes the JNLP container and any other necessary configurations.

2. Agent Pod Creation:
When a Jenkins job is triggered and requires an agent, Jenkins dynamically creates a new pod based on the configured pod template.

3. Docker Image Pull:
If the pod template specifies a Docker image from DockerHub (e.g., the JNLP container or any other tools), Jenkins will attempt to pull that image.

4. Jenkins as Docker Registry Proxy:
Jenkins acts as a proxy for DockerHub in this case. It pulls the necessary images from DockerHub and caches them locally.
The Jenkins master then serves as the registry for the Jenkins agents within the Kubernetes cluster.

5. Agent Pod Execution:
Once the pod is created and the necessary Docker images are available locally in the Jenkins master, the agent pod is launched with the specified containers.

// Shared pod template named 'default'
podTemplate(name: 'default', label: 'mypod', containers: [
    containerTemplate(name: 'maven', image: 'maven:alpine', command: 'cat', ttyEnabled: true),
    containerTemplate(name: 'git', image: 'git:alpine', command: 'cat', ttyEnabled: true)
])

pipeline {
    agent {
        kubernetes {
            inheritFrom 'default' // Inherit configurations from the 'default' pod template

            // Local override: Specify additional containers or modifications
            containers {
                containerTemplate(name: 'customContainer', image: 'custom/image', command: 'cat', ttyEnabled: true)
            }
        }
    }

    stages {
        stage('Checkout SCM') {
            steps {
                container('git') {
                    // Local step specific to the 'git' container
                    sh 'git clone URL'
                }
            }
        }
        stage('Build') {
            steps {
                container('maven') {
                    // Local step specific to the 'maven' container
                    sh 'mvn clean -DskipTests package'
                }
            }
        }
    }
}

If you don't provide any additional pod manifest in the kubernetes block and use inheritFrom 'default', Jenkins will use the inherited configurations as the pod template for the agent. In this scenario, the 'default' pod template would define the containers, images, volumes, and other settings for the agent pod.


---------------------------------------------------------------End to End pipeline----------------------------------------------------------------------
Pipeline includes pods as build agents,maven,nexus,sonarqube and helm

1. create k8s cluster on digital ocean and downlaod kubeconfig file locally
2. download helm and kubectl and set path 
3. install jenkins through helm chart
helm repo add jenkins https://charts.jenkins.io
helm repo update
helm pull jenkins/jenkins --untar			

helm upgrade --install jenkins jenkins/ 					--> you have to make below changes in values.yaml file and then execute
or 
helm upgrade --install jenkins jenkins/jenkins --set controller.servicePort=80 --set controller.serviceType=LoadBalancer		--> changing service type to loadbalancer so that jenkins can be directly accessible from outside cluster

kubectl exec -it jenkins-0 -- bash
cat /run/secrets/additional/chart-admin-password

pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
       '''}
     }
    stages{
        stage('Checkout SCM'){
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
              }
         }
  }


Note: if you want to run Jenkins as container then use helm chart to install jenkins. Jenkins if running as pod then it always spins JNLP container within all slave pods for communication and JNLP conrainer accepts task from jenkins on port 50000. when we install jenkins using helm chart, JNLP container (inbound agent) template configuration are in built. 

When using Jenkins with Kubernetes agents, the common approach for sharing files between containers in a pod is to use shared volumes. The emptyDir volume is one option. Jenkins uses the Kubernetes Plugin, which supports several ways of sharing data between containers in a pod. When you define a pod template in Jenkins using the Kubernetes Plugin, you can specify volumes that should be mounted into the containers.


----------------JUnit plugin + PVC for maven------------------
download JUnit plugin for showing unit test results and use PVC for maven so that maven will not download dependancies every time which will delay the job execution

#pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: maven-cache
spec:
  accessModes:
  - readWriteOnce
  resources:
    requests:
      storage: 1Gi

pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
	  volumeMounts:
          - name: maven-cache
            mountPath: /root/.m2/repository/
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
        volumes:
        - name: cache
          persistentVolumeClaim:
              claimName: maven-cache
 
       '''}
     }
    stages{
        stage('Checkout SCM'){
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
		post{
                     JUnit '**/target/reports/*.xml'
                     }
              }
         }
  }



--------sonar scan------
1. install sonarqube using helm charts
helm repo add sonarqube https://SonarSource.github.io/helm-chart-sonarqube
helm repo update
helm pull sonarqube/sonarqube --untar			--> update values.yaml and change service type as loadbalancer

helm upgrade --install sonarqube sonarqube/ 			--> password: admin
2. manage jenkins --> manage plugins --> download sonar scanner cli plugin 
3. manage jenkins ---> configure system --> system configuration --> add Sonarqube Server details and add sonarqube server credentials under global credentials security section of managed jenkins 
4. spin pod with sonar scanner cli 

pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
	  volumeMounts:
          - name: maven-cache
            mountPath: /root/.m2/repository/
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
        volumes:
        - name: cache
          persistentVolumeClaim:
              claimName: maven-cache
        - name: sonar-cli
          image: sonarsource/sonar-scanner-cli:latest
          command:
          - cat
          tty: true
       '''}
     }
    stages{
        stage('Checkout SCM'){
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
		post{
                     JUnit '**/target/reports/*.xml'
                     }
              }
         }
        stage('Sonar scan'){
           steps{
                container('sonar-cli'){
                 withSonarQubeEnv(credentialsId: 'sonar', installationName: 'sonarserver'){	--> withSonarQubeEnv() wrapper used to send scan details with server
                     sh ''' /opt/sonar-scanner/bin/sonar-scanner \  			--> execute sonar-scanner binary
			-Dsonar.projectKey=petclinic \
			-Dsonar.projectName=petcliic \
			-Dsonar.projectVersion=1.0 \
			-Dsonar.sources=src/main \
			-Dsonar.tests=src/test \
			-Dsonar.java.binaries=target/classes \
			-Dsonar.language=java \
			-Dsonar.sourceEncoding=UTF8 \
			-Dsonar.java.libraries=target/classes 
                       '''
                     }
                   }
                }
             }
          stage('Wait for quality gate'){
              steps{
                      container('sonar-cli'){
                         timeout(time: 1, unit: 'HOURS'){			--> create sonarqube-webhook in sonarqube so that it will send QG info to jenkins
                            waitForQualityGate abortPipeline: true		--> wait for quality get information to reach jenkins if not then abort pipeline
                            }
                          }
                    }
                }
          }


----------------send maven build to nexus------------------------
refer: https://artifacthub.io/packages/helm/sonatype/nexus-repository-manager

1. install nexus using helm chart
helm repo add sonatype https://sonatype.github.io/helm3-charts/
helm repo update
helm pull sonatype/nexus-repository-manager --untar

helm upgrade --install nexus nexus-repository-manager/
kubectl exec -it nexus-nexus-repository-manager-5745766765-5pjcf -- bash
cat /nexus-data/admin.password

2. download nexusArtifactUploader and pipeline utility steps plugin
3. manage jenkins --> global security --> credentials --> add nexus credentials as nexus-creds
4. spin pod with curl installed 

pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
	  volumeMounts:
          - name: maven-cache
            mountPath: /root/.m2/repository/
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
        volumes:
        - name: cache
          persistentVolumeClaim:
              claimName: maven-cache
        - name: sonar-cli
          image: sonarsource/sonar-scanner-cli:latest
          command:
          - cat
          tty: true
        - name: curl
          image: alpine/curl:latest
          command:
          - cat
          tty: true
       '''}
     }
     environment{
	NEXUS_PROTOCOL='http'
	NEXUS_VERSION='nexus3'
	NEXUS_URL='IP:8081'
	NEXUS_REPOSITORY='maven-hosted'
	NEXUS_CREDENTIAL_ID='nexus-creds'
         }

    stages{
        stage('Checkout SCM'){
	    when { expression { true } }
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
	     when { expression { true } }
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
		post{
                     JUnit '**/target/reports/*.xml'
                     }
              }
         }
        stage('Sonar scan'){
           when { expression { true } }
           steps{
                container('sonar-cli'){
                 withSonarQubeEnv(credentialsId: 'sonar', installationName: 'sonarserver'){	--> withSonarQubeEnv() wrapper used to send scan details with server
                     sh ''' /opt/sonar-scanner/bin/sonar-scanner \  			--> execute sonar-scanner binary
			-Dsonar.projectKey=petclinic \
			-Dsonar.projectName=petcliic \
			-Dsonar.projectVersion=1.0 \
			-Dsonar.sources=src/main \
			-Dsonar.tests=src/test \
			-Dsonar.java.binaries=target/classes \
			-Dsonar.language=java \
			-Dsonar.sourceEncoding=UTF8 \
			-Dsonar.java.libraries=target/classes 
                       '''
                     }
                   }
                }
             }
          stage('Wait for quality gate'){
              when { expression { true } }
              steps{
                      container('sonar-cli'){
                         timeout(time: 1, unit: 'HOURS'){			--> create sonarqube-webhook in sonarqube so that it will send QG info to jenkins
                            waitForQualityGate abortPipeline: true		--> wait for quality get information to reach jenkins if not then abort pipeline
                            }
                          }
                    }
                }
          stage('push maven to Nexus'){
	       when { expression { false } }
               steps{
                    container('jnlp'){
                          script{
				pom = readMavenPom file: "pom.xml";
				filesByGlob = findFiles(glob:"target/*.${pom.packaging}");
				artifactPath = filesByGlob[0].path;
				artifactExists = fileExists artifactPath;
				if (artifactExists){
					nexusArtifactUploader(
						nexusVersion: NEXUS_VERSION,
						protocol: NEXUS_PROTOCOL,
						nexusUrl: NEXUS_URL,
						groupId: pom.groupId,
						version: pom.version,
						repository: NEXUS_REPOSITORY,
						credential_Id: NEXUS_CREDENTIAL_ID,
						artifacts: [
						[artifactId: pom.artifactId,
						 classifiers: '',
						 file: artifactPath,
						 type: pom.packaging],
						
						[artifactId: pom.atifactId,
						 classifiers: '',
						 file: "pom.xml",
						 type: "pom"]
                                              ]
					);
						
				}else{
					echo "***FILE: ${artifactpath} could not be found";
				   }

                              }  
                          }
                       }
                  }
            stage('Push maven to nexus through CURL'){
	   	   when { expression { true } }
                   steps{
                        container('curl'){
                          script{
				withCredentials([usernamePassword(credentialsId:'nexus-creds', passwordVariable:'pass', userVariable:'usr')]){
					pom = readMavenPom file: "pom.xml";
					sh "curl -v -u $usr:$pass --upload-file target/${pom.artifactId}-${pom.version}-${pom.packaging} \
					http://$NEXUS_URL/repository/$NEXUS_REPOSITORY/org/springframework/samples/${pom.artifactId}/${pom.version}/							${pom.artifactId}-${pom.version}-${pom.packaging}"
						
					}
			        }
                             }
                        }
                    }

 		}
 	}
------------Build docker image from war file--------------------
1. spin docker cli container as k8s agent
2. add dockerhub credentials in manage jenkins --> global credentials --> credentials
3. mount /var/run/docker.sock hostPath in above container so that docker container (docker cli) can use of /var/run/docker.sock file to connect to docker daemon from host to perform docker commands. 
4. create dockerfile 
FROM openjdk:8-jre-alpine
COPY target/*.war /usr/bin/spring-petclinic.war
EXPOSE 8080
ENTRYPOINT ["java","-jar","/usr/bin/spring-petclinic.war","--server.port=8080"]


pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
	  volumeMounts:
          - name: maven-cache
            mountPath: /root/.m2/repository/
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
        - name: sonar-cli
          image: sonarsource/sonar-scanner-cli:latest
          command:
          - cat
          tty: true
        - name: curl
          image: alpine/curl:latest
          command:
          - cat
          tty: true
        - name: docker
          image: docker:latest
          command:
          - cat
          tty: true
          volumeMounts:
          - name: docker-sock
            mountPath: /var/run/docker.sock
        volumes:
        - name: cache
          persistentVolumeClaim:
              claimName: maven-cache
        - name: docker-sock
          hostpath: 
             path: /var/run/docker.sock
       '''}
     }
     environment{
	NEXUS_PROTOCOL='http'
	NEXUS_VERSION='nexus3'
	NEXUS_URL='IP:8081'
	NEXUS_REPOSITORY='maven-hosted'
	NEXUS_CREDENTIAL_ID='nexus-creds'
	DOCKERHUB_USER='shantayya'
	APP_NAME='petclinic'
	IMAGE_NAME="${DOCKERHUB_USER}"+ "/" + "${APP_NAME}"
	IMAGE_TAG=$BUILD_NUMBER
         }

    stages{
        stage('Checkout SCM'){
	    when { expression { true } }
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
	     when { expression { true } }
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
		post{
                     JUnit '**/target/reports/*.xml'
                     }
              }
         }
        stage('Sonar scan'){
           when { expression { true } }
           steps{
                container('sonar-cli'){
                 withSonarQubeEnv(credentialsId: 'sonar', installationName: 'sonarserver'){	--> withSonarQubeEnv() wrapper used to send scan details with server
                     sh ''' /opt/sonar-scanner/bin/sonar-scanner \  			--> execute sonar-scanner binary
			-Dsonar.projectKey=petclinic \
			-Dsonar.projectName=petcliic \
			-Dsonar.projectVersion=1.0 \
			-Dsonar.sources=src/main \
			-Dsonar.tests=src/test \
			-Dsonar.java.binaries=target/classes \
			-Dsonar.language=java \
			-Dsonar.sourceEncoding=UTF8 \
			-Dsonar.java.libraries=target/classes 
                       '''
                     }
                   }
                }
             }
          stage('Wait for quality gate'){
              when { expression { true } }
              steps{
                      container('sonar-cli'){
                         timeout(time: 1, unit: 'HOURS'){			--> create sonarqube-webhook in sonarqube so that it will send QG info to jenkins
                            waitForQualityGate abortPipeline: true		--> wait for quality get information to reach jenkins if not then abort pipeline
                            }
                          }
                    }
                }
          stage('push maven to Nexus'){
	       when { expression { false } }
               steps{
                    container('jnlp'){
                          script{
				pom = readMavenPom file: "pom.xml";
				filesByGlob = findFiles(glob:"target/*.${pom.packaging}");
				artifactPath = filesByGlob[0].path;
				artifactExists = fileExists artifactPath;
				if (artifactExists){
					nexusArtifactUploader(
						nexusVersion: NEXUS_VERSION,
						protocol: NEXUS_PROTOCOL,
						nexusUrl: NEXUS_URL,
						groupId: pom.groupId,
						version: pom.version,
						repository: NEXUS_REPOSITORY,
						credential_Id: NEXUS_CREDENTIAL_ID,
						artifacts: [
						[artifactId: pom.artifactId,
						 classifiers: '',
						 file: artifactPath,
						 type: pom.packaging],
						
						[artifactId: pom.atifactId,
						 classifiers: '',
						 file: "pom.xml",
						 type: "pom"]
                                              ]
					);
						
				}else{
					echo "***FILE: ${artifactpath} could not be found";
				   }

                              }  
                          }
                       }
                  }
            stage('Push maven to nexus through CURL'){
	   	   when { expression { true } }
                   steps{
                        container('curl'){
                          script{
				withCredentials([usernamePassword(credentialsId:'nexus-creds', passwordVariable:'pass', userVariable:'usr')]){
					pom = readMavenPom file: "pom.xml";
					sh "curl -v -u $usr:$pass --upload-file target/${pom.artifactId}-${pom.version}-${pom.packaging} \
					http://$NEXUS_URL/repository/$NEXUS_REPOSITORY/org/springframework/samples/${pom.artifactId}/${pom.version}/							${pom.artifactId}-${pom.version}-${pom.packaging}"
						
					}
			        }
                             }
                        }
                    }

	     stage('Docker build image'){
                   steps{
                        container('docker'){
					sh 'docker build -t $IMAGE_NAME:$IMAGE_TAG .'
					sh 'docker tag $IMAGE_NAME/$IMAGE_TAG $IMAGE_NAME:latest'
					withCredentials([usernamePassword(crdentialsId:'dockerhub', passwordVariable:'pass', userVariable:'user')]){
						sh 'docker login -u $user -p $pass'
						sh 'docker push $IMAGE_NAME/$IMAGE_TAG'
						sh 'docker push $IMAGE_NAME/latest'
                                         }
					sh 'docker rmi $IMAGE_NAME/$IMAGE_TAG'
					sh 'docker rmi $IMAGE_NAME/latest'
                                      }
                         }
                }
          }
   }


------------------Deploy to kubernetes cluster-----------------------
1. create dockerfile for creating image having helm and kubectl
FROM alpine/helm
RUN curl -LO https://dl.k8s.io/release/v1.25.0/bin/linux/amd64/kubectl \
    && mv kubectl /bin/kubectl \
    && chmod a+x /bin/kubectl

docker build -t helm-kubectl-cli .
docker push helm-kubectl-cli
 
2. download kubernetes cli plugin 
3. download kubeconfig file from digital ocean and manage jenkins --> manage credentials --> add secret file(kubeconfig file) as do-kc
4. download deployment.yaml file
apiVersion: v1
kind: Deployment
metadata:
  labels:
    app: petclinic
spec:
  replicas: 1
  selectors:
    matchLabels:
      app: petclinic
  template:
    metadata:
      labels:
        app: petclinic
    spec:
  	containers:
  	- name: petclinic
    	  image: shantayya/petclinc:latest
          ports:
          - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: petclinic
spec:
  type: Loadbalancer
  selector:
      app: petclinic
  ports:
  - port: 80
    containerPort: 8080
 
5. create  helm-kubectl container from step 1
pipeline{
  agent{
    kubernetes{
      //inheritFrom 'default'	
      yaml '''
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          name: test
      spec:
        containers:
        - name: maven
          image: maven:alpine
          command:
          - cat
          tty: true
	  volumeMounts:
          - name: maven-cache
            mountPath: /root/.m2/repository/
        - name: SCM
          image: git:alpine
          command: 
          - cat
          tty: true
        - name: sonar-cli
          image: sonarsource/sonar-scanner-cli:latest
          command:
          - cat
          tty: true
        - name: curl
          image: alpine/curl:latest
          command:
          - cat
          tty: true
        - name: docker
          image: docker:latest
          command:
          - cat
          tty: true
          volumeMounts:
          - name: docker-sock
            mountPath: /var/run/docker.sock
        - name: helm-kubectl-cli
          image: shantayya/helm-kubectl-cli
          command:
          - cat
          tty: true
        volumes:
        - name: cache
          persistentVolumeClaim:
              claimName: maven-cache
        - name: docker-sock
          hostpath: 
             path: /var/run/docker.sock
       '''}
     }
     environment{
	NEXUS_PROTOCOL='http'
	NEXUS_VERSION='nexus3'
	NEXUS_URL='IP:8081'
	NEXUS_REPOSITORY='maven-hosted'
	NEXUS_CREDENTIAL_ID='nexus-creds'
	DOCKERHUB_USER='shantayya'
	APP_NAME='petclinic'
	IMAGE_NAME="${DOCKERHUB_USER}"+ "/" + "${APP_NAME}"
	IMAGE_TAG=$BUILD_NUMBER
         }

    stages{
        stage('Checkout SCM'){
	    when { expression { true } }
            steps{
                container('git'){
                    sh 'git clone URL'
                              }
                   }
                }
         stage('Build'){
	     when { expression { true } }
             steps{
                 container('maven'){
                     sh 'mvn clean -DskipTests package'
                             }
                    }
		post{
                     JUnit '**/target/reports/*.xml'
                     }
              }
         }
        stage('Sonar scan'){
           when { expression { true } }
           steps{
                container('sonar-cli'){
                 withSonarQubeEnv(credentialsId: 'sonar', installationName: 'sonarserver'){	--> withSonarQubeEnv() wrapper used to send scan details with server
                     sh ''' /opt/sonar-scanner/bin/sonar-scanner \  			--> execute sonar-scanner binary
			-Dsonar.projectKey=petclinic \
			-Dsonar.projectName=petcliic \
			-Dsonar.projectVersion=1.0 \
			-Dsonar.sources=src/main \
			-Dsonar.tests=src/test \
			-Dsonar.java.binaries=target/classes \
			-Dsonar.language=java \
			-Dsonar.sourceEncoding=UTF8 \
			-Dsonar.java.libraries=target/classes 
                       '''
                     }
                   }
                }
             }
          stage('Wait for quality gate'){
              when { expression { true } }
              steps{
                      container('sonar-cli'){
                         timeout(time: 1, unit: 'HOURS'){			--> create sonarqube-webhook in sonarqube so that it will send QG info to jenkins
                            waitForQualityGate abortPipeline: true		--> wait for quality get information to reach jenkins if not then abort pipeline
                            }
                          }
                    }
                }
          stage('push maven to Nexus'){
	       when { expression { false } }
               steps{
                    container('jnlp'){
                          script{
				pom = readMavenPom file: "pom.xml";
				filesByGlob = findFiles(glob:"target/*.${pom.packaging}");
				artifactPath = filesByGlob[0].path;
				artifactExists = fileExists artifactPath;
				if (artifactExists){
					nexusArtifactUploader(
						nexusVersion: NEXUS_VERSION,
						protocol: NEXUS_PROTOCOL,
						nexusUrl: NEXUS_URL,
						groupId: pom.groupId,
						version: pom.version,
						repository: NEXUS_REPOSITORY,
						credential_Id: NEXUS_CREDENTIAL_ID,
						artifacts: [
						[artifactId: pom.artifactId,
						 classifiers: '',
						 file: artifactPath,
						 type: pom.packaging],
						
						[artifactId: pom.atifactId,
						 classifiers: '',
						 file: "pom.xml",
						 type: "pom"]
                                              ]
					);
						
				}else{
					echo "***FILE: ${artifactpath} could not be found";
				   }

                              }  
                          }
                       }
                  }
            stage('Push maven to nexus through CURL'){
	   	   when { expression { true } }
                   steps{
                        container('curl'){
                          script{
				withCredentials([usernamePassword(credentialsId:'nexus-creds', passwordVariable:'pass', userVariable:'usr')]){
					pom = readMavenPom file: "pom.xml";
					sh "curl -v -u $usr:$pass --upload-file target/${pom.artifactId}-${pom.version}-${pom.packaging} \
					http://$NEXUS_URL/repository/$NEXUS_REPOSITORY/org/springframework/samples/${pom.artifactId}/${pom.version}/							${pom.artifactId}-${pom.version}-${pom.packaging}"
						
					}
			        }
                             }
                        }
                    }

	     stage('Docker build image'){
                   steps{
                        container('docker'){
					sh 'docker build -t $IMAGE_NAME:$IMAGE_TAG .'
					sh 'docker tag $IMAGE_NAME/$IMAGE_TAG $IMAGE_NAME:latest'
					withCredentials([usernamePassword(crdentialsId:'dockerhub', passwordVariable:'pass', userVariable:'user')]){
						sh 'docker login -u $user -p $pass'
						sh 'docker push $IMAGE_NAME/$IMAGE_TAG'
						sh 'docker push $IMAGE_NAME/latest'
                                         }
					sh 'docker rmi $IMAGE_NAME/$IMAGE_TAG'
					sh 'docker rmi $IMAGE_NAME/latest'
                                      }
                         }
                }
          }
            stage('Deploy to kubernetes'){
                steps{
                      container('helm-kubectl-cli'){
			   script{
				withKubeConfig([credentialsId='do_kc']){		--> withKubeConfig() wrapper is scripted syntax so used in script block
   	           		sh 'kubectl deploy -f deployment.yaml'
        	    		}
			    }
		 	  }
		     }
                } 
   }



--------------------------GitOps with ArgoCD-----------------------------



